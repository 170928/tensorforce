{
  "batch_size": 4000,
  "discount": 0.99,
  "gae_lambda": 0.97,

  "optimizer": {
    "type": "adam",
    "learning_rate": 0.01
  },

  "baseline_mode": "states",
  "baseline": {
    "type": "mlp",
    "sizes": [32, 32]
  },
  "baseline_optimizer": {
    "type": "multi_step",
    "optimizer": {
      "type": "adam",
      "learning_rate": 0.01
    },
    "num_steps": 5
  }
}
